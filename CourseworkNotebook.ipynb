{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to AI - Coursework\n",
    "Joshua Luke Boddy - aczc760\n",
    "\n",
    "Saeed Almansoori - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do\n",
    "- Functions to prepare each column of the dataset we need\n",
    "- Decide on learning model (Multivariate regression?)\n",
    "- Research integer value return (Possible with Regression)\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "Taking a CSV file as our data set, the data needs to be converted across from CSV to something program readable as well as formatting the data into a readable format for our model (undecided).\n",
    "\n",
    "Columns needing data conversion:\n",
    "- Manufacturer Name -> Categorical\n",
    "- Model Name -> Categorical\n",
    "- Transmission -> Categorical\n",
    "- Color -> Categorical\n",
    "- Engine Fuel -> Categorical\n",
    "- Engine Has Gas -> Boolean\n",
    "- Engine Type -> Categorical\n",
    "- Body Type -> Categorical\n",
    "- Has Warranty -> Boolean\n",
    "- State -> Categorical\n",
    "- Drivetrain -> Categorical\n",
    "\n",
    "Extra Useable Columns\n",
    "- Odometer Value -> Int\n",
    "- Year Produced -> Int\n",
    "- Engine Capacity -> Float\n",
    "\n",
    "Data Labels\n",
    "- Price USD -> Float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "\n",
    "The libraries below are required for the whole project and are imported at the start to maintain tidiness in the code, as well as make them usable throughout the notebook in later cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data Set from CSV\n",
    "\n",
    "Reading the CSV file in to a data structure is simple using the pandas library as it has a built-in `read_csv` function that converts the data automatically (better than the alternative `with open(FILENAME, 'r') as file` option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "manufacturer_name     object\nmodel_name            object\ntransmission          object\ncolor                 object\nodometer_value         int64\nyear_produced          int64\nengine_fuel           object\nengine_has_gas          bool\nengine_type           object\nengine_capacity      float64\nbody_type             object\nhas_warranty            bool\nstate                 object\ndrivetrain            object\nprice_usd            float64\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "columnList = [\n",
    "    'manufacturer_name',\n",
    "    'model_name',\n",
    "    'transmission',\n",
    "    'color',\n",
    "    'engine_fuel',\n",
    "    'engine_has_gas',\n",
    "    'engine_type',\n",
    "    'body_type',\n",
    "    'has_warranty',\n",
    "    'state',\n",
    "    'drivetrain',\n",
    "    'odometer_value',\n",
    "    'year_produced',\n",
    "    'engine_capacity',\n",
    "    'price_usd'\n",
    "]\n",
    "\n",
    "data = pd.read_csv('./cars.csv', usecols=columnList)\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation Functions for Each Column\n",
    "\n",
    "Each column needs to be converted to a numerical data type so that it is readable by the neural network, this is done for each column below, however as opposed to writing functions for each column, we can determine what type the column is at the moment and write functions for each of those types respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert From Object\n",
    "def convertFromObject(column):\n",
    "    # This one liner takes a categorical column\n",
    "    # and assigns a value to each value in the column\n",
    "    # then returns the new column as a list of ints\n",
    "    return column.astype('category').cat.codes\n",
    "\n",
    "# Convert From Boolean\n",
    "def convertFromBoolean(column):\n",
    "    # Simply convert from boolean to integer\n",
    "    # where 0 is False and 1 is True\n",
    "    return column.astype(int)\n",
    "\n",
    "# Prepare Column function for each column\n",
    "# This contains the appropriate function for\n",
    "# each column in the dataset to run by\n",
    "# checking their data types\n",
    "def prepare_column(dtype, column):\n",
    "    if dtype == np.object:\n",
    "        return convertFromObject(column)\n",
    "    elif dtype == np.bool:\n",
    "        return convertFromBoolean(column)\n",
    "    elif dtype == np.int or dtype == np.float:\n",
    "        return column\n",
    "    else:\n",
    "        raise Exception(\"Data Type for Current Column %s not specified\" % (column.dtype))\n",
    "\n",
    "# The overall preparation function\n",
    "#Â This will prepare every column in the dataset\n",
    "# to be read by the neural network\n",
    "def prepare_dataset(dataset):\n",
    "    for column in dataset.columns:\n",
    "        dataset[column] = prepare_column(dataset[column].dtype, dataset[column])\n",
    "    dataset.dropna()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Functions to Prepare the Data\n",
    "\n",
    "Below we are applying the functions defined in the previous section to our dataset to make it readable by the neural network. This is important as mathematical operations later won't be able to be performed on the data if it is not in readable format, and as such the network will not function at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = prepare_dataset(data).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation\n",
    "TBD when we confirm whether we can use multivariate regression or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "        def __init__(self, layers=[14, 28, 28, 1], learningRate=0.001):\n",
    "            # Adjusted the code here so that the neural network parameters were customisable\n",
    "            # Same as before, hard coded values are stored in a dictionary and generated\n",
    "            # based on the sizes of the input, hidden and output layer sizes\n",
    "            self.layers = layers\n",
    "            self.learningRate = learningRate\n",
    "            self.params = {}\n",
    "            for i in range(1, len(self.layers)):\n",
    "                self.params['W' + str(i)] = np.random.uniform(-1, 1, size=(self.layers[i - 1], self.layers[i]))\n",
    "                self.params['B' + str(i)] = np.random.uniform(-1, 1, size=(self.layers[i]))\n",
    "        \n",
    "        def forwardPass(self, X):\n",
    "            params = self.params\n",
    "            params['A0'] = np.array(X)\n",
    "            for i in range(1, len(self.layers)):\n",
    "                params['Z' + str(i)] = np.dot(params['A' + str(i - 1)], params['W' + str(i)]) + params['B' + str(i)]\n",
    "                if(i == len(self.layers) - 1):\n",
    "                    params['A' + str(i)] = params['Z' + str(i)]\n",
    "                else:\n",
    "                    params['A' + str(i)] = params['Z' + str(i)]\n",
    "            return params[\"A\" + str(len(self.layers) - 1)]\n",
    "        \n",
    "        def backwardPass(self, Y, output):\n",
    "            params = self.params\n",
    "            changes = {}\n",
    "            placeholder = self.params\n",
    "            for i in reversed(range(1, len(self.layers))):\n",
    "                if (i == len(self.layers) - 1):\n",
    "                    error = 2 * (output - Y) / output.shape[0] * self.relu(params['Z' + str(i)], derivative=True)\n",
    "                    changes['W' + str(i)] = np.outer(error, params['A' + str(i - 1)])\n",
    "                else:\n",
    "                    error = np.dot(error, params['W' + str(i + 1)].T) * self.relu(params['Z' + str(i)], derivative=True)\n",
    "                    changes['W' + str(i)] = np.outer(error, params[\"A\" + str(i - 1)])\n",
    "            return changes\n",
    "        \n",
    "        def updateParams(self, changes):\n",
    "            for key, value in changes.items():\n",
    "                self.params[key] -= self.learningRate * np.transpose(value)\n",
    "        \n",
    "        def classify(self, X):\n",
    "            output = self.forwardPass(X)\n",
    "            return output\n",
    "            \n",
    "        @staticmethod   \n",
    "        def sigmoid(x, derivative = False):\n",
    "            if derivative:\n",
    "                return ((1/(1+np.exp(-x))) * (1 - 1/(1+np.exp(-x))))\n",
    "            return 1/(1+np.exp(-x))\n",
    "        \n",
    "        @staticmethod\n",
    "        def relu(x, derivative=False):\n",
    "            if derivative:\n",
    "                x[x<=0] = 0\n",
    "                x[x>0] = 1\n",
    "                return x\n",
    "            return np.maximum(0, x)\n",
    "        \n",
    "        @staticmethod \n",
    "        def softmax(x, derivative = False):\n",
    "            exps = np.exp(x - x.max())\n",
    "            if derivative:\n",
    "                return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "            return exps / np.sum(exps, axis=0)\n",
    "        \n",
    "        \n",
    "        def train(self, X, Y, epochs):\n",
    "            print(len(X))\n",
    "            print(len(Y))\n",
    "            for i in range (0, epochs):\n",
    "                for j, x in X.iterrows():\n",
    "                    output = self.forwardPass(x)\n",
    "                    changes = self.backwardPass(Y[j], output)\n",
    "                    self.updateParams(changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-766194.08921564]\n38521\n38521\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5286\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5269\u001b[0m         ):\n\u001b[0;32m-> 5270\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute '_name'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-f57b1e0e5384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarsNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcarsNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-283-7c638218e749>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, Y, epochs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforwardPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0mchanges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackwardPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5286\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "carsNN = NeuralNetwork()\n",
    "\n",
    "X = data.loc[:, data.columns != \"price_usd\"]\n",
    "Y = data.pop(\"price_usd\")\n",
    "\n",
    "print(carsNN.classify(X.loc[1]))\n",
    "carsNN.train(X, Y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(carsNN.classify(X.loc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}